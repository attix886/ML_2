### ML训练营_2笔记
**基本工作** 
* 必备的包：lightgbm LightGBM基于梯度提升决策树的包
* 百度Paddle飞浆/jupyter

**Baseline基本逻辑**
* 载入数据->提取特征&数据集拆分->设置模型参数->时间特征提取转化->训练模型并进行预测->计算MAE并生成提交文件

**lgb_params参数设置（不太理解的）**
* metric='mae' 设置平均误差为评估指标
* nthread=16 并行线程数
* lamda_12=10 L2正则化权重，用于控制模型的复杂度

**回调函数no_info** 
* lgb.callback.log_evaluation(period=-1) 禁用训练日志输出 （lgb通常会输出一些训练过程的信息，这样禁用后更简洁）

**Q&A**
* pandas保存文件函数的参数值 index=False 表示不生成索引值
* 随机种子是为了保证每次迭代使用的是相同数据集

--------------------------------------------------------------------------------------------------------------------
### ML训练营_3笔记
**主要模块**
* 1.问题建模：
首先要对赛题、对业务要有充分的理解，包括对赛题的数据，比如数据集之间的关系，缺失值情况等；也包括各种评价指标，比如分类指标的准确率、召回率，回归指标的MAE等。
* 2.数据探索性分析：
要了解数据（包括类型，数据干净的程度，缺失值情况，特征间是否冗余，数据的分布情况，是否存在时间信息比如数据穿越）。
* 3.特征工程：
数据的预处理：比如对离群值、缺失值、明显错误值的处理，特征提取（编码、统计量、交叉统计、离散化）还有要注意如何对时间特征进行处理（时序相关特征 历史平移、滑窗统计等）
在特征选择中：综合考虑过滤法（比如相关性的排序 卡方检验 互信息等）、封装法（向前向后搜索）、嵌入法（基于学习模型的特征排序）
必备模型：XGBoost LightGBM NN模型
* 4.模型融合：
可以有各种融合的方式，不要局限于单单一种：比如 训练过程融合、训练结果融合
当然 在融合的时候，也尽量不要让XGBoost和Lightgbm融合，因为这俩都是梯度上升决策树的集成的模型，可以尝试互相之间原理各不同的融合方式，比如可以和NN融合。

